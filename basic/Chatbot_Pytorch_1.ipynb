{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0821bc47",
   "metadata": {},
   "source": [
    "# Viraj Nishesh Darji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb7327dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\VIRAJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e525a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2f29c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e0d8525",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abb1636",
   "metadata": {},
   "source": [
    "Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a338023",
   "metadata": {},
   "source": [
    "Tokenization is breaking text into smaller parts, that smaller parts are called tokens, tokens can be words or sentences. It helps in understanding meaning of the text by analyizing tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70faf1f8",
   "metadata": {},
   "source": [
    "split sentence into array of words/tokens </br>\n",
    "a token can be a word or punctuation character, or number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b290cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c5403d",
   "metadata": {},
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c6cec2",
   "metadata": {},
   "source": [
    "Stemming and Lemmatization are methods to reduce words to their base form. In stemming the resuling base form word we get may not be lexicographically correct, while in lemmatization the words will be lexicographically correct. There stemming is faster and lemmtization is more accurate, it depends on use case what you want to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6237b22",
   "metadata": {},
   "source": [
    "stemming = find the root form of the word</br>\n",
    "examples:</br>\n",
    "words = [\"organize\", \"organizes\", \"organizing\"]</br>\n",
    "words = [stem(w) for w in words]</br>\n",
    "-> [\"organ\", \"organ\", \"organ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c7853c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are also lowering the words.\n",
    "def stem(word):\n",
    "    return stemmer.stem(word.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3c8185",
   "metadata": {},
   "source": [
    "Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74517c9",
   "metadata": {},
   "source": [
    "Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3a42c3",
   "metadata": {},
   "source": [
    "Bag of Words is one of the popular word embedding technique. Each valued vector would represents count of words in a text. It does not contain information on the grammer or the order of the words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8afb80",
   "metadata": {},
   "source": [
    "return bag of words array:</br>\n",
    "1 for each known word that exists in the sentence, 0 otherwise</br>\n",
    "example:</br>\n",
    "sentence = [\"hello\", \"how\", \"are\", \"you\"]</br>\n",
    "words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]</br>\n",
    "bog   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a305e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(tokenized_sentence, words):\n",
    "    # stem each word\n",
    "    sentence_words = [stem(word) for word in tokenized_sentence]\n",
    "    # initialize bag with 0 for each word\n",
    "    bag = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, w in enumerate(words):\n",
    "        if w in sentence_words: \n",
    "            bag[idx] = 1\n",
    "\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0425b087",
   "metadata": {},
   "source": [
    "Creating a Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340cbb44",
   "metadata": {},
   "source": [
    "It has 3 linear Layer and activation function is relu</br>\n",
    "Activation Function is ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905c8f2e",
   "metadata": {},
   "source": [
    "__init__ function defines layers.  </br>\n",
    "Example below l1 is Linear Layer </br>\n",
    "__forward__ pass function is used for computing prediction. </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7c65c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size) \n",
    "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1758472",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json', 'r') as f:\n",
    "    intents = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3b9e500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hey :-)', 'Hello, thanks for visiting', 'Hi there, what can I do for you?', 'Hi there, how can I help?']}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}, {'tag': 'items', 'patterns': ['Which items do you have?', 'What kinds of items are there?', 'What do you sell?'], 'responses': ['We sell coffee and tea', 'We have coffee and tea']}, {'tag': 'payments', 'patterns': ['Do you take credit cards?', 'Do you accept Mastercard?', 'Can I pay with Paypal?', 'Are you cash only?'], 'responses': ['We accept VISA, Mastercard and Paypal', 'We accept most major credit cards, and Paypal']}, {'tag': 'delivery', 'patterns': ['How long does delivery take?', 'How long does shipping take?', 'When do I get my delivery?'], 'responses': ['Delivery takes 2-4 days', 'Shipping takes 2-4 days']}, {'tag': 'funny', 'patterns': ['Tell me a joke!', 'Tell me something funny!', 'Do you know a joke?'], 'responses': ['Why did the hipster burn his mouth? He drank the coffee before it was cool.', 'What did the buffalo say when his son left for college? Bison.']}]}\n"
     ]
    }
   ],
   "source": [
    "print(intents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16dfe0d",
   "metadata": {},
   "source": [
    "Creating list of all words, list of tags and pair of tokenized words and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a040fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "# loop through each sentence in our intents patterns\n",
    "for intent in intents['intents']:\n",
    "    tag = intent['tag']\n",
    "    # add to tag list\n",
    "    tags.append(tag)\n",
    "    for pattern in intent['patterns']:\n",
    "        # tokenize each word in the sentence\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        # add to our words list\n",
    "        all_words.extend(w)\n",
    "        # add to xy pair\n",
    "        xy.append((w, tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04670182",
   "metadata": {},
   "source": [
    "Removing punctuation, then stemming and making list of all_words and tags unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "721620f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem and lower each word\n",
    "ignore_words = ['?', '.', '!']\n",
    "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
    "# remove duplicates and sort\n",
    "all_words = sorted(set(all_words))\n",
    "tags = sorted(set(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c190db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 patterns\n",
      "7 tags: ['delivery', 'funny', 'goodbye', 'greeting', 'items', 'payments', 'thanks']\n",
      "54 unique stemmed words: [\"'s\", 'a', 'accept', 'anyon', 'are', 'bye', 'can', 'card', 'cash', 'credit', 'day', 'deliveri', 'do', 'doe', 'funni', 'get', 'good', 'goodby', 'have', 'hello', 'help', 'hey', 'hi', 'how', 'i', 'is', 'item', 'joke', 'kind', 'know', 'later', 'long', 'lot', 'mastercard', 'me', 'my', 'of', 'onli', 'pay', 'paypal', 'see', 'sell', 'ship', 'someth', 'take', 'tell', 'thank', 'that', 'there', 'what', 'when', 'which', 'with', 'you']\n"
     ]
    }
   ],
   "source": [
    "print(len(xy), \"patterns\")\n",
    "print(len(tags), \"tags:\", tags)\n",
    "print(len(all_words), \"unique stemmed words:\", all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca84682",
   "metadata": {},
   "source": [
    "Creating Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0742f9b5",
   "metadata": {},
   "source": [
    "Since training data should be in form of vectors and not words, we are applying bag of words to all_words list and using index we are converting tags to numbers and finally creating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe1d06a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for (pattern_sentence, tag) in xy:\n",
    "    # X: bag of words for each pattern_sentence\n",
    "    bag = bag_of_words(pattern_sentence, all_words)\n",
    "    X_train.append(bag)\n",
    "    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n",
    "    label = tags.index(tag)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac84ae0",
   "metadata": {},
   "source": [
    "Defining all the Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1198d319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 7\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters \n",
    "num_epochs = 1000\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "input_size = len(X_train[0])\n",
    "hidden_size = 8\n",
    "output_size = len(tags)\n",
    "print(input_size, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e687f92",
   "metadata": {},
   "source": [
    "Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e68d743",
   "metadata": {},
   "source": [
    "pytorch Dataset have many inbuilt datasets.\n",
    "If you want to create custom dataset, you can create it, you need to define 3 functions in it. </br>\n",
    "__init__ function initiates the loading of the dataset, where we define features and labels. </br>\n",
    "__get_item__ function is used to return sample from dataset based on index. </br>\n",
    "__len__ function returns number of sample in the dataset. </br>\n",
    "DataLoader is then used to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22fb221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(X_train)\n",
    "        self.x_data = X_train\n",
    "        self.y_data = y_train\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4026849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChatDataset()\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb56cf51",
   "metadata": {},
   "source": [
    "we are calling the  neural network that we defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52b3ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a48176",
   "metadata": {},
   "source": [
    "CrossEntrophyLoss already applied softmax and Negative Log Likelihood Loss </br>\n",
    "Loss is used to calculate loss, which will then be used in backpropogation to get gradient. The lower the loss, better the accuracy </br>\n",
    "Optimizer is then used update weight in back propogation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "692e4e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8145190",
   "metadata": {},
   "source": [
    "Training loop consists of 3 parts: </br>\n",
    "    Forward Pass : Compute Prediction </br>\n",
    "    Backward Pass : gradient </br>\n",
    "    Update Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3ca6b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.9669\n",
      "Epoch [200/1000], Loss: 0.2731\n",
      "Epoch [300/1000], Loss: 0.0331\n",
      "Epoch [400/1000], Loss: 0.0398\n",
      "Epoch [500/1000], Loss: 0.0102\n",
      "Epoch [600/1000], Loss: 0.0123\n",
      "Epoch [700/1000], Loss: 0.0018\n",
      "Epoch [800/1000], Loss: 0.0022\n",
      "Epoch [900/1000], Loss: 0.0016\n",
      "Epoch [1000/1000], Loss: 0.0006\n",
      "final loss: 0.0006\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for (words, labels) in train_loader:\n",
    "        words = words.to(device)\n",
    "        labels = labels.to(dtype=torch.long).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(words)\n",
    "        # if y would be one-hot, we must apply\n",
    "        # labels = torch.max(labels, 1)[1]\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "print(f'final loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121e4167",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6eaf672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete. file saved to data.pth\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "\"model_state\": model.state_dict(),\n",
    "\"input_size\": input_size,\n",
    "\"hidden_size\": hidden_size,\n",
    "\"output_size\": output_size,\n",
    "\"all_words\": all_words,\n",
    "\"tags\": tags\n",
    "}\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "torch.save(data, FILE)\n",
    "\n",
    "print(f'training complete. file saved to {FILE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e541a31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (l1): Linear(in_features=54, out_features=8, bias=True)\n",
       "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
       "  (l3): Linear(in_features=8, out_features=7, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model.state_dict())\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc656d7",
   "metadata": {},
   "source": [
    "Bot will calculate the probability and identify the tag from the intent json file. </br>\n",
    "To whichever tag it identifies the most, it will give q random response from that tag.  </br>\n",
    "If bot do not identify the tag, it will say I do not understand.  </br>\n",
    "If you want to stop chatting, just type quit  </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54adfcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's chat! (type 'quit' to exit)\n",
      "You: what is your name?\n",
      "Sam: See you later, thanks for visiting\n",
      "You: tell me a joke?\n",
      "Sam: What did the buffalo say when his son left for college? Bison.\n",
      "You: hii\n",
      "Sam: Hey :-)\n",
      "You: whats up?\n",
      "Sam: We sell coffee and tea\n",
      "You: quit\n"
     ]
    }
   ],
   "source": [
    "bot_name = \"Sam\"\n",
    "print(\"Let's chat! (type 'quit' to exit)\")\n",
    "while True:\n",
    "    # sentence = \"do you use credit cards?\"\n",
    "    sentence = input(\"You: \")\n",
    "    if sentence == \"quit\":\n",
    "        break\n",
    "\n",
    "    sentence = tokenize(sentence)\n",
    "    X = bag_of_words(sentence, all_words)\n",
    "    X = X.reshape(1, X.shape[0])\n",
    "    X = torch.from_numpy(X).to(device)\n",
    "\n",
    "    output = model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "    tag = tags[predicted.item()]\n",
    "\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    if prob.item() > 0.75:\n",
    "        for intent in intents['intents']:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
    "    else:\n",
    "        print(f\"{bot_name}: I do not understand...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60420048",
   "metadata": {},
   "source": [
    "References: </br>\n",
    "1. Chat Bot With PyTorch - NLP And Deep Learning - Python Tutorial (Part 1). (2020, June 8). YouTube. https://www.youtube.com/watch?v=RpWeNzfSUHw&list=PLC-Eil48AiqUlPLB8HGRABtydUOFL84DH </br>\n",
    "2. PyTorch Tutorial 06 - Training Pipeline: Model, Loss, and Optimizer. (2019, December 28). YouTube. https://www.youtube.com/watch?v=VVDHU_TWwUg&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=7 </br>\n",
    "3. G. (2017, September 9). Contextual Chatbots with Tensorflow. Medium. https://chatbotsmagazine.com/contextual-chat-bots-with-tensorflow-4391749d0077 </br>\n",
    "4. P. (2020, September 4). GitHub - patrickloeber/pytorch-chatbot: Simple chatbot implementation with PyTorch. GitHub. https://github.com/patrickloeber/pytorch-chatbot </br>\n",
    "5. Recurrent Neural Network (RNN) Tutorial: Types and Examples [Updated] | Simplilearn. (n.d.). Simplilearn.com. https://www.simplilearn.com/tutorials/deep-learning-tutorial/rnn </br>\n",
    "6. Datasets & DataLoaders — PyTorch Tutorials 2.0.0+cu117 documentation. (n.d.). Datasets & DataLoaders — PyTorch Tutorials 2.0.0+cu117 Documentation. https://pytorch.org/tutorials/beginner/basics/data_tutorial.html </br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
